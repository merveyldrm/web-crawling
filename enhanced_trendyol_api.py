#!/usr/bin/env python3
"""
GeliÅŸmiÅŸ Trendyol API Scripti
1000+ yorum Ã§ekebilen optimize edilmiÅŸ sistem
"""

import requests
import json
import time
import csv
from datetime import datetime
from urllib.parse import urlparse, parse_qs

class EnhancedTrendyolAPI:
    def __init__(self):
        self.session = requests.Session()
        self.base_headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'tr-TR,tr;q=0.9,en;q=0.8',
            'Referer': 'https://www.trendyol.com/',
            'Origin': 'https://www.trendyol.com'
        }
        self.session.headers.update(self.base_headers)
        
        # API endpoint'leri
        self.api_endpoints = {
            'reviews': 'https://apigw.trendyol.com/discovery-web-socialgw-service/reviews',
            'product_reviews': 'https://apigw.trendyol.com/discovery-web-websfxsocialreviewrating-santral/product-reviews-detailed',
            'review_likes': 'https://apigw.trendyol.com/discovery-web-socialgw-service/api/review-like/filter'
        }
        
        # Rate limiting
        self.request_delay = 1.0  # saniye
        self.max_retries = 3
        
    def extract_product_info(self, url):
        """URL'den Ã¼rÃ¼n bilgilerini Ã§Ä±kar"""
        try:
            # URL'yi parse et
            parsed = urlparse(url)
            path_parts = parsed.path.split('/')
            
            # ÃœrÃ¼n ID'sini bul
            product_id = None
            for part in path_parts:
                if part.startswith('p-'):
                    product_id = part.replace('p-', '')
                    break
            
            # Seller ID'sini URL'den Ã§Ä±kar
            seller_id = None
            query_params = parse_qs(parsed.query)
            if 'merchantId' in query_params:
                seller_id = query_params['merchantId'][0]
            elif 'boutiqueId' in query_params:
                seller_id = query_params['boutiqueId'][0]
            
            return {
                'product_id': product_id,
                'seller_id': seller_id,
                'url': url
            }
        except Exception as e:
            print(f"URL parse hatasÄ±: {e}")
            return None
    
    def get_reviews_via_api(self, product_info, page=1, limit=50):
        """API Ã¼zerinden yorumlarÄ± Ã§ek"""
        try:
            # API endpoint'i
            url = f"{self.api_endpoints['product_reviews']}"
            
            # Parametreler
            params = {
                'sellerId': product_info['seller_id'],
                'contentId': product_info['product_id'],
                'page': page,
                'order': 'DESC',
                'orderBy': 'Score',
                'channelId': 1
            }
            
            # Ä°stek gÃ¶nder
            response = self.session.get(url, params=params, timeout=10)
            
            if response.status_code == 200:
                return response.json()
            else:
                print(f"API HatasÄ±: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"API Ã§aÄŸrÄ±sÄ± hatasÄ±: {e}")
            return None
    
    def get_reviews_via_web(self, product_info, page=1):
        """Web sayfasÄ± Ã¼zerinden yorumlarÄ± Ã§ek"""
        try:
            # Yorumlar sayfasÄ± URL'si
            reviews_url = f"{product_info['url']}/yorumlar"
            
            # Parametreler
            params = {
                'boutiqueId': product_info['seller_id'],
                'merchantId': product_info['seller_id'],
                'page': page
            }
            
            # Ä°stek gÃ¶nder
            response = self.session.get(reviews_url, params=params, timeout=10)
            
            if response.status_code == 200:
                return response.json()
            else:
                print(f"Web API HatasÄ±: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"Web API Ã§aÄŸrÄ±sÄ± hatasÄ±: {e}")
            return None
    
    def parse_reviews_data(self, data):
        """API yanÄ±tÄ±ndan yorumlarÄ± parse et"""
        reviews = []
        
        try:
            if isinstance(data, dict):
                # FarklÄ± API yanÄ±t formatlarÄ±nÄ± kontrol et
                if 'result' in data and isinstance(data['result'], dict):
                    # HTML iÃ§eriÄŸi varsa parse et
                    html_content = data['result'].get('html', '')
                    if html_content:
                        reviews = self.parse_html_reviews(html_content)
                
                elif 'data' in data and isinstance(data['data'], list):
                    reviews = data['data']
                
                elif 'reviews' in data and isinstance(data['reviews'], list):
                    reviews = data['reviews']
                
                elif 'items' in data and isinstance(data['items'], list):
                    reviews = data['items']
                
                else:
                    # Ham veriyi kontrol et
                    reviews = self.extract_reviews_from_raw_data(data)
            
            return reviews
            
        except Exception as e:
            print(f"Veri parse hatasÄ±: {e}")
            return []
    
    def parse_html_reviews(self, html_content):
        """HTML iÃ§eriÄŸinden yorumlarÄ± Ã§Ä±kar"""
        reviews = []
        
        try:
            # Basit HTML parsing (gerÃ§ek uygulamada BeautifulSoup kullanÄ±labilir)
            import re
            
            # Yorum pattern'leri
            comment_patterns = [
                r'<div[^>]*class="[^"]*comment[^"]*"[^>]*>(.*?)</div>',
                r'<div[^>]*class="[^"]*review[^"]*"[^>]*>(.*?)</div>',
                r'<p[^>]*class="[^"]*comment-text[^"]*"[^>]*>(.*?)</p>'
            ]
            
            for pattern in comment_patterns:
                matches = re.findall(pattern, html_content, re.DOTALL)
                for match in matches:
                    # HTML tag'lerini temizle
                    clean_text = re.sub(r'<[^>]+>', '', match).strip()
                    if clean_text and len(clean_text) > 10:
                        reviews.append({
                            'comment': clean_text,
                            'source': 'html_parsed'
                        })
            
            return reviews
            
        except Exception as e:
            print(f"HTML parse hatasÄ±: {e}")
            return []
    
    def extract_reviews_from_raw_data(self, data):
        """Ham veriden yorumlarÄ± Ã§Ä±kar"""
        reviews = []
        
        try:
            # JSON string'i dict'e Ã§evir
            if isinstance(data, str):
                data = json.loads(data)
            
            # Recursive olarak yorumlarÄ± ara
            def find_reviews(obj, path=""):
                if isinstance(obj, dict):
                    for key, value in obj.items():
                        current_path = f"{path}.{key}" if path else key
                        
                        # Yorum benzeri alanlarÄ± kontrol et
                        if any(keyword in key.lower() for keyword in ['comment', 'review', 'text', 'content']):
                            if isinstance(value, str) and len(value) > 10:
                                reviews.append({
                                    'comment': value,
                                    'field': key,
                                    'source': 'raw_data'
                                })
                        
                        # Recursive arama
                        find_reviews(value, current_path)
                
                elif isinstance(obj, list):
                    for i, item in enumerate(obj):
                        current_path = f"{path}[{i}]"
                        find_reviews(item, current_path)
            
            find_reviews(data)
            return reviews
            
        except Exception as e:
            print(f"Ham veri parse hatasÄ±: {e}")
            return []
    
    def get_all_reviews(self, product_url, target_count=1000, max_pages=50):
        """TÃ¼m yorumlarÄ± Ã§ek"""
        print(f"ğŸ¯ Hedef: {target_count} yorum Ã§ekmek")
        
        # ÃœrÃ¼n bilgilerini Ã§Ä±kar
        product_info = self.extract_product_info(product_url)
        if not product_info:
            print("âŒ ÃœrÃ¼n bilgileri Ã§Ä±karÄ±lamadÄ±")
            return []
        
        print(f"ğŸ“¦ ÃœrÃ¼n ID: {product_info['product_id']}")
        print(f"ğŸª Seller ID: {product_info['seller_id']}")
        
        all_reviews = []
        page = 1
        
        while len(all_reviews) < target_count and page <= max_pages:
            print(f"\nğŸ“„ Sayfa {page} Ã§ekiliyor... (Mevcut: {len(all_reviews)} yorum)")
            
            # API'den yorumlarÄ± Ã§ek
            api_data = self.get_reviews_via_api(product_info, page=page)
            
            if api_data:
                reviews = self.parse_reviews_data(api_data)
                if reviews:
                    all_reviews.extend(reviews)
                    print(f"âœ… API'den {len(reviews)} yorum alÄ±ndÄ±")
                else:
                    print("âš ï¸ API'den yorum alÄ±namadÄ±, web API deneniyor...")
                    
                    # Web API'yi dene
                    web_data = self.get_reviews_via_web(product_info, page=page)
                    if web_data:
                        web_reviews = self.parse_reviews_data(web_data)
                        if web_reviews:
                            all_reviews.extend(web_reviews)
                            print(f"âœ… Web API'den {len(web_reviews)} yorum alÄ±ndÄ±")
            
            # Rate limiting
            time.sleep(self.request_delay)
            page += 1
            
            # EÄŸer yeni yorum gelmiyorsa dur
            if page > 3 and len(all_reviews) == 0:
                print("âŒ HiÃ§ yorum alÄ±namadÄ±")
                break
        
        print(f"\nğŸ‰ Toplam {len(all_reviews)} yorum Ã§ekildi!")
        return all_reviews[:target_count]  # Hedef sayÄ±da yorum dÃ¶ndÃ¼r
    
    def save_reviews_to_csv(self, reviews, filename=None):
        """YorumlarÄ± CSV dosyasÄ±na kaydet"""
        if not reviews:
            print("âŒ Kaydedilecek yorum bulunamadÄ±")
            return
        
        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"trendyol_reviews_{timestamp}.csv"
        
        try:
            with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                fieldnames = ['comment', 'user', 'date', 'rating', 'seller', 'source']
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for review in reviews:
                    # Eksik alanlarÄ± doldur
                    review_data = {
                        'comment': review.get('comment', ''),
                        'user': review.get('user', 'Anonim'),
                        'date': review.get('date', ''),
                        'rating': review.get('rating', ''),
                        'seller': review.get('seller', ''),
                        'source': review.get('source', 'api')
                    }
                    writer.writerow(review_data)
            
            print(f"âœ… {len(reviews)} yorum {filename} dosyasÄ±na kaydedildi")
            
        except Exception as e:
            print(f"âŒ CSV kaydetme hatasÄ±: {e}")
    
    def analyze_reviews(self, reviews):
        """YorumlarÄ± analiz et"""
        if not reviews:
            print("âŒ Analiz edilecek yorum bulunamadÄ±")
            return
        
        print(f"\nğŸ“Š Yorum Analizi:")
        print(f"   - Toplam yorum: {len(reviews)}")
        
        # Kaynak daÄŸÄ±lÄ±mÄ±
        sources = {}
        for review in reviews:
            source = review.get('source', 'unknown')
            sources[source] = sources.get(source, 0) + 1
        
        print(f"   - Kaynak daÄŸÄ±lÄ±mÄ±:")
        for source, count in sources.items():
            print(f"     * {source}: {count} yorum")
        
        # Ortalama yorum uzunluÄŸu
        total_length = sum(len(str(review.get('comment', ''))) for review in reviews)
        avg_length = total_length / len(reviews) if reviews else 0
        print(f"   - Ortalama yorum uzunluÄŸu: {avg_length:.1f} karakter")

def main():
    """Ana fonksiyon"""
    print("ğŸš€ GeliÅŸmiÅŸ Trendyol API Sistemi")
    print("=" * 50)
    
    # URL al
    url = input("Trendyol Ã¼rÃ¼n URL'sini girin: ").strip()
    if not url:
        print("âŒ URL gerekli!")
        return
    
    # Hedef yorum sayÄ±sÄ±nÄ± al
    target_input = input("Hedef yorum sayÄ±sÄ±nÄ± girin (varsayÄ±lan: 1000): ").strip()
    target_count = int(target_input) if target_input else 1000
    
    # API instance'Ä± oluÅŸtur
    api = EnhancedTrendyolAPI()
    
    try:
        # YorumlarÄ± Ã§ek
        reviews = api.get_all_reviews(url, target_count=target_count)
        
        if reviews:
            # Analiz et
            api.analyze_reviews(reviews)
            
            # CSV'ye kaydet
            api.save_reviews_to_csv(reviews)
            
            print(f"\nğŸ¯ BaÅŸarÄ±lÄ±! {len(reviews)} yorum Ã§ekildi ve kaydedildi.")
        else:
            print("âŒ HiÃ§ yorum Ã§ekilemedi")
    
    except Exception as e:
        print(f"âŒ Hata oluÅŸtu: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
