#!/usr/bin/env python3
"""
ğŸš€ Basit RAG Demo - Python 3.13 Uyumlu
Trendyol yorumlarÄ± iÃ§in minimal RAG sistemi
"""

import os
import json
import pandas as pd
import numpy as np
from datetime import datetime
from typing import List, Dict, Any
import sqlite3
import hashlib

# Mevcut sistem import'larÄ±
try:
    from src.analyzers.advanced_comment_analyzer import AdvancedCommentAnalyzer
    from src.analyzers.priority_analyzer import PriorityAnalyzer
    print("âœ… Mevcut analiz modÃ¼lleri yÃ¼klendi")
except ImportError as e:
    print(f"âš ï¸ Analiz modÃ¼lleri yÃ¼klenemedi: {e}")
    print("ğŸ’¡ Temel versiyonla devam edilecek")

class SimpleRAGSystem:
    def __init__(self, db_path: str = "simple_rag.db"):
        """Basit RAG sistemi - TF-IDF tabanlÄ±"""
        self.db_path = db_path
        self.init_database()
        
        # Analiz modÃ¼lleri
        try:
            self.comment_analyzer = AdvancedCommentAnalyzer()
            self.priority_analyzer = PriorityAnalyzer()
            self.has_analyzers = True
        except:
            self.has_analyzers = False
            print("âš ï¸ Analiz modÃ¼lleri olmadan Ã§alÄ±ÅŸÄ±lacak")
        
        # Basit TF-IDF iÃ§in stop words
        self.stop_words = {
            'bir', 'bu', 'da', 'de', 'ile', 'iÃ§in', 'Ã§ok', 'var', 'yok', 'olan',
            've', 'ama', 'fakat', 'ancak', 'ÅŸey', 'ÅŸu', 'o', 'ben', 'sen', 'biz',
            'siz', 'onlar', 'hiÃ§', 'her', 'ne', 'nasÄ±l', 'neden', 'kim', 'hangi'
        }
        
        print("âœ… Basit RAG sistemi hazÄ±r")
    
    def init_database(self):
        """SQLite veritabanÄ±nÄ± baÅŸlat"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS comments (
                id INTEGER PRIMARY KEY,
                user TEXT,
                date TEXT,
                comment TEXT,
                comment_hash TEXT UNIQUE,
                category TEXT DEFAULT 'unknown',
                priority_score REAL DEFAULT 0,
                processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS knowledge_base (
                id INTEGER PRIMARY KEY,
                category TEXT,
                problem TEXT,
                solution TEXT,
                keywords TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        print("ğŸ“ SQLite veritabanÄ± hazÄ±r")
    
    def get_comment_hash(self, comment: str, user: str = "", date: str = "") -> str:
        """Yorum iÃ§in unique hash"""
        text = f"{comment}{user}{date}"
        return hashlib.md5(text.encode()).hexdigest()
    
    def load_comments_from_csv(self, csv_file: str = "trendyol_comments.csv") -> int:
        """CSV'den yorumlarÄ± yÃ¼kle"""
        if not os.path.exists(csv_file):
            print(f"âŒ {csv_file} bulunamadÄ±!")
            return 0
        
        try:
            df = pd.read_csv(csv_file, encoding='utf-8')
            print(f"ğŸ“Š {len(df)} yorum bulundu")
        except Exception as e:
            print(f"âŒ CSV okuma hatasÄ±: {e}")
            return 0
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        loaded_count = 0
        
        for _, row in df.iterrows():
            comment = str(row.get('comment', ''))
            user = str(row.get('user', ''))
            date = str(row.get('date', ''))
            
            if not comment.strip():
                continue
            
            comment_hash = self.get_comment_hash(comment, user, date)
            
            # Analiz yap (eÄŸer modÃ¼ller varsa)
            category = 'unknown'
            priority_score = 0
            
            if self.has_analyzers:
                try:
                    analysis = self.comment_analyzer.analyze_comment(comment)
                    priority = self.priority_analyzer.analyze_comment_priority(comment)
                    
                    category = analysis.get('category_analysis', {}).get('highest_category', 'unknown')
                    priority_score = priority.get('priority_score', 0)
                except:
                    pass
            
            # VeritabanÄ±na ekle
            try:
                cursor.execute('''
                    INSERT OR IGNORE INTO comments 
                    (user, date, comment, comment_hash, category, priority_score)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (user, date, comment, comment_hash, category, priority_score))
                
                if cursor.rowcount > 0:
                    loaded_count += 1
            except Exception as e:
                print(f"âš ï¸ Yorum ekleme hatasÄ±: {e}")
        
        conn.commit()
        conn.close()
        
        print(f"âœ… {loaded_count} yorum veritabanÄ±na eklendi")
        return loaded_count
    
    def add_knowledge(self, category: str, problem: str, solution: str, keywords: List[str] = None):
        """Bilgi tabanÄ±na entry ekle"""
        if keywords is None:
            keywords = []
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO knowledge_base (category, problem, solution, keywords)
            VALUES (?, ?, ?, ?)
        ''', (category, problem, solution, ','.join(keywords)))
        
        conn.commit()
        conn.close()
        
        print(f"ğŸ“š Bilgi eklendi: {category} - {problem[:50]}...")
    
    def simple_text_similarity(self, text1: str, text2: str) -> float:
        """Basit TF-IDF benzerlik hesaplama"""
        def tokenize(text: str) -> set:
            words = text.lower().split()
            return {word for word in words if word not in self.stop_words and len(word) > 2}
        
        tokens1 = tokenize(text1)
        tokens2 = tokenize(text2)
        
        if not tokens1 or not tokens2:
            return 0.0
        
        intersection = tokens1.intersection(tokens2)
        union = tokens1.union(tokens2)
        
        return len(intersection) / len(union) if union else 0.0
    
    def search_similar_comments(self, query: str, limit: int = 5) -> List[Dict]:
        """Benzer yorumlarÄ± ara"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT * FROM comments')
        all_comments = cursor.fetchall()
        
        similarities = []
        
        for comment_row in all_comments:
            comment_id, user, date, comment, comment_hash, category, priority_score, processed_at = comment_row
            
            similarity = self.simple_text_similarity(query, comment)
            
            if similarity > 0.1:  # Minimum benzerlik eÅŸiÄŸi
                similarities.append({
                    'id': comment_id,
                    'user': user,
                    'date': date,
                    'comment': comment,
                    'category': category,
                    'priority_score': priority_score,
                    'similarity': similarity
                })
        
        # Benzerlik skoruna gÃ¶re sÄ±rala
        similarities.sort(key=lambda x: x['similarity'], reverse=True)
        
        conn.close()
        return similarities[:limit]
    
    def search_knowledge_base(self, query: str, limit: int = 3) -> List[Dict]:
        """Bilgi tabanÄ±nda ara"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT * FROM knowledge_base')
        all_knowledge = cursor.fetchall()
        
        results = []
        
        for knowledge_row in all_knowledge:
            kb_id, category, problem, solution, keywords, created_at = knowledge_row
            
            # Problem ve solution'da ara
            problem_sim = self.simple_text_similarity(query, problem)
            solution_sim = self.simple_text_similarity(query, solution)
            keyword_sim = self.simple_text_similarity(query, keywords)
            
            max_sim = max(problem_sim, solution_sim, keyword_sim)
            
            if max_sim > 0.1:
                results.append({
                    'id': kb_id,
                    'category': category,
                    'problem': problem,
                    'solution': solution,
                    'keywords': keywords.split(',') if keywords else [],
                    'similarity': max_sim
                })
        
        results.sort(key=lambda x: x['similarity'], reverse=True)
        
        conn.close()
        return results[:limit]
    
    def query(self, question: str) -> Dict[str, Any]:
        """RAG sorgusu"""
        print(f"ğŸ” Soru: {question}")
        
        # 1. Benzer yorumlarÄ± bul
        similar_comments = self.search_similar_comments(question, limit=3)
        
        # 2. Bilgi tabanÄ±nÄ± ara
        knowledge_results = self.search_knowledge_base(question, limit=2)
        
        # 3. Basit yanÄ±t oluÅŸtur
        answer_parts = []
        
        if similar_comments:
            answer_parts.append("**Benzer Yorumlardan Bulgular:**")
            for i, comment in enumerate(similar_comments, 1):
                priority = comment['priority_score']
                category = comment['category']
                answer_parts.append(f"{i}. {comment['comment'][:100]}... (Ã–ncelik: {priority:.0f}/100, Kategori: {category})")
        
        if knowledge_results:
            answer_parts.append("\n**Bilgi TabanÄ±ndan Ã–neriler:**")
            for i, kb in enumerate(knowledge_results, 1):
                answer_parts.append(f"{i}. **{kb['category']}**: {kb['solution']}")
        
        if not answer_parts:
            answer_parts.append("Bu soru iÃ§in ilgili bilgi bulunamadÄ±.")
        
        answer = "\n".join(answer_parts)
        
        return {
            "question": question,
            "answer": answer,
            "similar_comments": similar_comments,
            "knowledge_results": knowledge_results,
            "timestamp": datetime.now().isoformat()
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """Sistem istatistikleri"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT COUNT(*) FROM comments')
        total_comments = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM knowledge_base')
        total_knowledge = cursor.fetchone()[0]
        
        cursor.execute('SELECT category, COUNT(*) FROM comments GROUP BY category')
        category_dist = dict(cursor.fetchall())
        
        cursor.execute('SELECT AVG(priority_score) FROM comments WHERE priority_score > 0')
        avg_priority = cursor.fetchone()[0] or 0
        
        conn.close()
        
        return {
            "total_comments": total_comments,
            "total_knowledge_entries": total_knowledge,
            "category_distribution": category_dist,
            "average_priority": round(avg_priority, 2),
            "has_advanced_analyzers": self.has_analyzers
        }


def setup_demo_knowledge(rag):
    """Demo bilgi tabanÄ±nÄ± kur"""
    print("ğŸŒ Demo bilgi tabanÄ± kuruluyor...")
    
    knowledge_entries = [
        {
            "category": "kargo",
            "problem": "Kargo gecikmesi ve teslimat sorunlarÄ±",
            "solution": "1) Alternatif kargo firmalarÄ± ile anlaÅŸma yapÄ±n, 2) Express teslimat seÃ§eneÄŸi sunun, 3) SMS/Email takip sistemi kurun",
            "keywords": ["kargo", "teslimat", "gecikme", "geÃ§"]
        },
        {
            "category": "kalite",
            "problem": "ÃœrÃ¼n kalitesi ve bozuk Ã¼rÃ¼n ÅŸikayetleri",
            "solution": "1) Kalite kontrol sÃ¼reÃ§lerini sÄ±kÄ±laÅŸtÄ±rÄ±n, 2) TedarikÃ§i denetimi yapÄ±n, 3) Kusurlu Ã¼rÃ¼nler iÃ§in hÄ±zlÄ± iade prosedÃ¼rÃ¼",
            "keywords": ["kalite", "bozuk", "defolu", "kÃ¶tÃ¼"]
        },
        {
            "category": "beden",
            "problem": "Beden uyumsuzluÄŸu ve kalÄ±p sorunlarÄ±",
            "solution": "1) Beden tablosunu gÃ¼ncelleyin, 2) AR deneme Ã¶zelliÄŸi ekleyin, 3) MÃ¼ÅŸteri yorumlarÄ±ndan beden Ã¶nerileri",
            "keywords": ["beden", "uyum", "kalÄ±p", "bÃ¼yÃ¼k", "kÃ¼Ã§Ã¼k"]
        },
        {
            "category": "musteri_hizmetleri",
            "problem": "MÃ¼ÅŸteri hizmetleri yanÄ±t sÃ¼resi ve kalitesi",
            "solution": "1) 24/7 chat desteÄŸi kurun, 2) YanÄ±t sÃ¼resini 2 saate dÃ¼ÅŸÃ¼rÃ¼n, 3) Ã‡ok dilli destek saÄŸlayÄ±n",
            "keywords": ["mÃ¼ÅŸteri", "hizmet", "destek", "yanÄ±t"]
        },
        {
            "category": "fiyat",
            "problem": "Fiyat algÄ±sÄ± ve deÄŸer sorunlarÄ±",
            "solution": "1) Rekabet analizi yapÄ±n, 2) Kampanya ve indirim sistemi kurun, 3) DeÄŸer algÄ±sÄ±nÄ± artÄ±racak iÃ§erikler",
            "keywords": ["fiyat", "pahalÄ±", "deÄŸer", "ucuz"]
        }
    ]
    
    for entry in knowledge_entries:
        rag.add_knowledge(
            entry["category"],
            entry["problem"],
            entry["solution"],
            entry["keywords"]
        )
    
    print("âœ… Demo bilgi tabanÄ± kuruldu")


def main():
    """Ana demo fonksiyonu"""
    print("ğŸš€ BASÄ°T RAG SÄ°STEMÄ° DEMO")
    print("=" * 50)
    print("Python 3.13 uyumlu, minimal baÄŸÄ±mlÄ±lÄ±k")
    
    # RAG sistemini baÅŸlat
    rag = SimpleRAGSystem()
    
    # CSV'den yorumlarÄ± yÃ¼kle
    doc_count = rag.load_comments_from_csv("trendyol_comments.csv")
    if doc_count == 0:
        print("âš ï¸ CSV dosyasÄ± bulunamadÄ± veya yÃ¼klenemedi")
        print("ğŸ’¡ Ã–nce trendyol_selenium_scraper.py Ã§alÄ±ÅŸtÄ±rarak yorum toplayÄ±n")
        return
    
    # Demo bilgi tabanÄ±nÄ± kur
    setup_demo_knowledge(rag)
    
    # Sistem istatistikleri
    stats = rag.get_stats()
    print(f"\nğŸ“Š SÄ°STEM Ä°STATÄ°STÄ°KLERÄ°:")
    print(f"   ğŸ“ Toplam Yorum: {stats['total_comments']}")
    print(f"   ğŸ“š Bilgi TabanÄ±: {stats['total_knowledge_entries']}")
    print(f"   ğŸ“ˆ Ortalama Ã–ncelik: {stats['average_priority']}/100")
    print(f"   ğŸ”§ GeliÅŸmiÅŸ Analiz: {'âœ…' if stats['has_advanced_analyzers'] else 'âŒ'}")
    
    # Demo sorgularÄ±
    demo_questions = [
        "Kargo sorunlarÄ± hakkÄ±nda ÅŸikayetler var mÄ±?",
        "ÃœrÃ¼n kalitesi ile ilgili ne tÃ¼r sorunlar yaÅŸanÄ±yor?",
        "Beden uyumsuzluÄŸu iÃ§in ne Ã¶nerirsin?",
        "MÃ¼ÅŸteri hizmetleri nasÄ±l iyileÅŸtirilebilir?",
        "En yÃ¼ksek Ã¶ncelikli problemler neler?"
    ]
    
    print(f"\nğŸ’¬ DEMO SORGULARI:")
    print("=" * 50)
    
    for question in demo_questions:
        print(f"\nâ“ SORU: {question}")
        print("-" * 40)
        
        result = rag.query(question)
        print(f"ğŸ¤– YANIT:\n{result['answer']}")
        print(f"ğŸ“Š Bulunan benzer yorum: {len(result['similar_comments'])}")
        print(f"ğŸ“š Bilgi tabanÄ± sonucu: {len(result['knowledge_results'])}")
    
    print(f"\nâœ… DEMO TAMAMLANDI!")
    print("\nğŸ’¡ GeliÅŸmiÅŸ Ã¶zellikler iÃ§in:")
    print("   - LangChain kurulumu: pip install langchain chromadb")
    print("   - Web arayÃ¼zÃ¼: streamlit run rag_chat_interface.py")


if __name__ == "__main__":
    main() 