import asyncio
import json
import time
import hashlib
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from pathlib import Path
import threading
from queue import Queue
import sqlite3
from dataclasses import dataclass
import schedule

# External imports for RAG
try:
    from sentence_transformers import SentenceTransformer
    import numpy as np
    from sklearn.metrics.pairwise import cosine_similarity
    import openai  # OpenAI API for enhanced text generation
except ImportError:
    print("‚ö†Ô∏è Bazƒ± RAG k√ºt√ºphaneleri eksik. 'pip install sentence-transformers openai' √ßalƒ±≈ütƒ±rƒ±n")

from advanced_comment_analyzer import AdvancedCommentAnalyzer
from priority_analyzer import PriorityAnalyzer
from topic_modeling_analyzer import TopicModelingAnalyzer

@dataclass
class ExternalSource:
    name: str
    url: str
    source_type: str  # 'api', 'web_scrape', 'document'
    update_frequency: str  # 'hourly', 'daily', 'weekly'
    last_updated: Optional[datetime] = None

class RAGKnowledgeBase:
    def __init__(self, db_path: str = "rag_knowledge.db"):
        self.db_path = db_path
        self.embedding_model = None
        self.init_database()
        
        # Sentence transformer for embeddings
        try:
            self.embedding_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
            print("‚úÖ Embedding modeli y√ºklendi")
        except Exception as e:
            print(f"‚ö†Ô∏è Embedding modeli y√ºklenemedi: {e}")
    
    def init_database(self):
        """SQLite veritabanƒ±nƒ± ba≈ülat"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Harici bilgi kaynaklarƒ± tablosu
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS external_sources (
                id INTEGER PRIMARY KEY,
                source_name TEXT UNIQUE,
                content TEXT,
                embedding BLOB,
                url TEXT,
                source_type TEXT,
                last_updated TIMESTAMP,
                relevance_score REAL DEFAULT 0.0
            )
        ''')
        
        # √úr√ºn bilgileri tablosu
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS product_info (
                id INTEGER PRIMARY KEY,
                product_name TEXT,
                brand TEXT,
                category TEXT,
                technical_specs TEXT,
                official_description TEXT,
                embedding BLOB,
                last_updated TIMESTAMP
            )
        ''')
        
        # Yorum ge√ßmi≈üi tablosu
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS comment_history (
                id INTEGER PRIMARY KEY,
                comment_hash TEXT UNIQUE,
                comment_text TEXT,
                analysis_result TEXT,
                priority_score REAL,
                timestamp TIMESTAMP,
                processed BOOLEAN DEFAULT 0
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def add_external_source(self, source_name: str, content: str, url: str, source_type: str):
        """Harici kaynak ekle ve embedding olu≈ütur"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Embedding olu≈ütur
        embedding = None
        if self.embedding_model:
            try:
                embedding_vector = self.embedding_model.encode([content])[0]
                embedding = embedding_vector.tobytes()
            except Exception as e:
                print(f"‚ö†Ô∏è Embedding olu≈üturulamadƒ±: {e}")
        
        cursor.execute('''
            INSERT OR REPLACE INTO external_sources 
            (source_name, content, embedding, url, source_type, last_updated)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (source_name, content, embedding, url, source_type, datetime.now()))
        
        conn.commit()
        conn.close()
        
        print(f"‚úÖ Harici kaynak eklendi: {source_name}")
    
    def find_relevant_context(self, query: str, limit: int = 3) -> List[Dict]:
        """Query'ye en yakƒ±n harici kaynaklarƒ± bul"""
        if not self.embedding_model:
            return []
        
        try:
            query_embedding = self.embedding_model.encode([query])[0]
        except Exception:
            return []
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('SELECT source_name, content, url, embedding FROM external_sources WHERE embedding IS NOT NULL')
        results = []
        
        for row in cursor.fetchall():
            source_name, content, url, embedding_bytes = row
            
            try:
                stored_embedding = np.frombuffer(embedding_bytes, dtype=np.float32)
                similarity = cosine_similarity([query_embedding], [stored_embedding])[0][0]
                
                results.append({
                    'source_name': source_name,
                    'content': content[:500] + '...' if len(content) > 500 else content,
                    'url': url,
                    'similarity': float(similarity)
                })
            except Exception:
                continue
        
        conn.close()
        
        # Benzerlik skoruna g√∂re sƒ±rala
        results.sort(key=lambda x: x['similarity'], reverse=True)
        return results[:limit]

class RealTimeCommentMonitor:
    def __init__(self, check_interval: int = 300):  # 5 dakika
        self.check_interval = check_interval
        self.comment_analyzer = AdvancedCommentAnalyzer()
        self.priority_analyzer = PriorityAnalyzer()
        self.topic_analyzer = TopicModelingAnalyzer()
        self.rag_kb = RAGKnowledgeBase()
        
        self.comment_queue = Queue()
        self.is_running = False
        self.last_check = datetime.now()
        
        # Otomatik raporlama
        self.auto_reports = {
            'hourly_priority': True,
            'daily_summary': True,
            'weekly_trend': True
        }
    
    def load_current_comments(self) -> List[Dict]:
        """Mevcut yorumlarƒ± y√ºkle"""
        return self.comment_analyzer.load_comments_from_csv("trendyol_comments.csv")
    
    def get_comment_hash(self, comment: Dict) -> str:
        """Yorum i√ßin hash olu≈ütur (tekrar kontrol√º i√ßin)"""
        comment_str = f"{comment.get('comment', '')}{comment.get('user', '')}{comment.get('date', '')}"
        return hashlib.md5(comment_str.encode()).hexdigest()
    
    def check_for_new_comments(self) -> List[Dict]:
        """Yeni yorumlarƒ± kontrol et"""
        current_comments = self.load_current_comments()
        new_comments = []
        
        conn = sqlite3.connect(self.rag_kb.db_path)
        cursor = conn.cursor()
        
        for comment in current_comments:
            comment_hash = self.get_comment_hash(comment)
            
            # Bu yorum daha √∂nce i≈ülendi mi?
            cursor.execute('SELECT id FROM comment_history WHERE comment_hash = ?', (comment_hash,))
            if not cursor.fetchone():
                new_comments.append(comment)
                
                # Yeni yorumu veritabanƒ±na ekle
                cursor.execute('''
                    INSERT INTO comment_history (comment_hash, comment_text, timestamp)
                    VALUES (?, ?, ?)
                ''', (comment_hash, comment.get('comment', ''), datetime.now()))
        
        conn.commit()
        conn.close()
        
        return new_comments
    
    def enhanced_analysis_with_rag(self, comments: List[Dict]) -> Dict:
        """RAG destekli geli≈ümi≈ü analiz"""
        if not comments:
            return {'message': 'Yeni yorum bulunamadƒ±'}
        
        print(f"üîç {len(comments)} yeni yorum analiz ediliyor...")
        
        # 1. Temel analizler
        analysis_results = self.comment_analyzer.analyze_all_comments(comments)
        priority_results = self.priority_analyzer.analyze_critical_issues(comments, analysis_results)
        
        # 2. RAG ile harici baƒülam bulma
        enhanced_results = analysis_results.copy()
        enhanced_results['rag_context'] = {}
        
        for category in analysis_results.get('category_analysis', {}):
            # Her kategori i√ßin harici kaynaklardan bilgi al
            category_comments = analysis_results['category_analysis'][category]
            
            if category_comments.get('negative'):
                # Negatif yorumlar i√ßin harici √ß√∂z√ºmler ara
                query = f"{category} problemi √ß√∂z√ºm√º √∂neri iyile≈ütirme"
                context = self.rag_kb.find_relevant_context(query, limit=2)
                
                enhanced_results['rag_context'][category] = {
                    'external_solutions': context,
                    'query_used': query
                }
        
        # 3. AI destekli √∂neriler (eƒüer OpenAI key varsa)
        enhanced_results['ai_recommendations'] = self.generate_ai_recommendations(priority_results)
        
        return {
            'analysis_results': enhanced_results,
            'priority_results': priority_results,
            'new_comments_count': len(comments),
            'analysis_timestamp': datetime.now().isoformat(),
            'rag_enhanced': True
        }
    
    def generate_ai_recommendations(self, priority_results: Dict) -> Dict:
        """AI destekli √∂neriler olu≈ütur"""
        recommendations = {}
        
        try:
            # OpenAI API key kontrol√º (√ßevresel deƒüi≈üken olarak)
            import os
            if not os.getenv('OPENAI_API_KEY'):
                return {'message': 'OpenAI API key bulunamadƒ± (opsiyonel)'}
            
            openai.api_key = os.getenv('OPENAI_API_KEY')
            
            critical_issues = priority_results.get('critical_issues', {})
            
            for category, data in critical_issues.items():
                if data['priority_score'] > 60:  # Sadece y√ºksek √∂ncelik
                    
                    prompt = f"""
                    E-ticaret kategorisi: {category}
                    √ñncelik skoru: {data['priority_score']}/100
                    ≈ûikayet sayƒ±sƒ±: {data['total_negative_comments']}
                    Sorumlu departman: {data['category_info']['department']}
                    
                    Bu kategori i√ßin 3 spesifik, uygulanabilir iyile≈ütirme √∂nerisi ver:
                    """
                    
                    response = openai.ChatCompletion.create(
                        model="gpt-3.5-turbo",
                        messages=[{"role": "user", "content": prompt}],
                        max_tokens=200,
                        temperature=0.7
                    )
                    
                    recommendations[category] = {
                        'ai_suggestions': response.choices[0].message.content,
                        'priority_score': data['priority_score']
                    }
        
        except Exception as e:
            return {'error': f'AI √∂neriler olu≈üturulamadƒ±: {e}'}
        
        return recommendations
    
    def start_monitoring(self):
        """Ger√ßek zamanlƒ± izlemeyi ba≈ülat"""
        self.is_running = True
        print("üöÄ Ger√ßek zamanlƒ± yorum izleme ba≈ülatƒ±ldƒ±!")
        print(f"‚è∞ Kontrol aralƒ±ƒüƒ±: {self.check_interval} saniye")
        
        # Scheduled tasks
        schedule.every().hour.do(self.hourly_priority_check)
        schedule.every().day.at("09:00").do(self.daily_summary_report)
        schedule.every().week.do(self.weekly_trend_report)
        
        while self.is_running:
            try:
                # 1. Yeni yorumlarƒ± kontrol et
                new_comments = self.check_for_new_comments()
                
                if new_comments:
                    print(f"üìù {len(new_comments)} yeni yorum bulundu!")
                    
                    # 2. RAG destekli analiz yap
                    enhanced_analysis = self.enhanced_analysis_with_rag(new_comments)
                    
                    # 3. Sonu√ßlarƒ± kaydet ve bildir
                    self.save_realtime_analysis(enhanced_analysis)
                    self.notify_if_critical(enhanced_analysis)
                
                # 4. Scheduled g√∂revleri √ßalƒ±≈ütƒ±r
                schedule.run_pending()
                
                # 5. Bekle
                time.sleep(self.check_interval)
                
            except KeyboardInterrupt:
                print("\n‚èπÔ∏è ƒ∞zleme durduruldu")
                break
            except Exception as e:
                print(f"‚ùå ƒ∞zleme hatasƒ±: {e}")
                time.sleep(30)  # Hata durumunda biraz bekle
    
    def stop_monitoring(self):
        """ƒ∞zlemeyi durdur"""
        self.is_running = False
        print("‚èπÔ∏è Ger√ßek zamanlƒ± izleme durduruldu")
    
    def hourly_priority_check(self):
        """Saatlik √∂ncelik kontrol√º"""
        print("‚è∞ Saatlik √∂ncelik kontrol√º yapƒ±lƒ±yor...")
        
        comments = self.load_current_comments()
        if len(comments) < 10:
            return
        
        analysis = self.comment_analyzer.analyze_all_comments(comments)
        priority = self.priority_analyzer.analyze_critical_issues(comments, analysis)
        
        # Acil durumlarƒ± kontrol et
        critical_issues = priority.get('critical_issues', {})
        urgent_count = sum(1 for cat, data in critical_issues.items() if data['priority_score'] >= 80)
        
        if urgent_count > 0:
            self.send_urgent_alert(f"üö® {urgent_count} acil kategori tespit edildi!")
    
    def daily_summary_report(self):
        """G√ºnl√ºk √∂zet raporu"""
        print("üìä G√ºnl√ºk √∂zet raporu olu≈üturuluyor...")
        
        # Son 24 saatin yorumlarƒ±nƒ± analiz et
        # (Bu √∂rnekte t√ºm yorumlarƒ± kullanƒ±yoruz)
        comments = self.load_current_comments()
        
        if comments:
            enhanced_analysis = self.enhanced_analysis_with_rag(comments)
            
            # G√ºnl√ºk rapor dosyasƒ± olu≈ütur
            daily_report_file = f"daily_report_{datetime.now().strftime('%Y%m%d')}.json"
            with open(daily_report_file, 'w', encoding='utf-8') as f:
                json.dump(enhanced_analysis, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"üìÑ G√ºnl√ºk rapor kaydedildi: {daily_report_file}")
    
    def weekly_trend_report(self):
        """Haftalƒ±k trend raporu"""
        print("üìà Haftalƒ±k trend raporu olu≈üturuluyor...")
        # Haftalƒ±k trendleri analiz etme kodu buraya gelecek
    
    def save_realtime_analysis(self, analysis: Dict):
        """Ger√ßek zamanlƒ± analiz sonu√ßlarƒ±nƒ± kaydet"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"realtime_analysis_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(analysis, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"üíæ Ger√ßek zamanlƒ± analiz kaydedildi: {filename}")
    
    def notify_if_critical(self, analysis: Dict):
        """Kritik durumda bildirim g√∂nder"""
        priority_results = analysis.get('priority_results', {})
        critical_issues = priority_results.get('critical_issues', {})
        
        urgent_categories = [
            cat for cat, data in critical_issues.items() 
            if data['priority_score'] >= 80
        ]
        
        if urgent_categories:
            alert_message = f"üö® ACƒ∞L: {', '.join(urgent_categories)} kategorilerinde kritik sorunlar tespit edildi!"
            self.send_urgent_alert(alert_message)
    
    def send_urgent_alert(self, message: str):
        """Acil durum bildirimi g√∂nder"""
        print(f"\n{'='*60}")
        print(f"üö® ACƒ∞L DURUM Bƒ∞LDƒ∞Rƒ∞Mƒ∞ üö®")
        print(f"‚è∞ Zaman: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"üì¢ Mesaj: {message}")
        print(f"{'='*60}\n")
        
        # Burada email, SMS, Slack vb. entegrasyonlarƒ± eklenebilir
        # send_email(message)
        # send_slack_notification(message)

class ExternalDataCollector:
    def __init__(self, rag_kb: RAGKnowledgeBase):
        self.rag_kb = rag_kb
        self.sources = [
            ExternalSource("Trendyol Yardƒ±m", "https://yardim.trendyol.com", "web_scrape", "daily"),
            ExternalSource("M√º≈üteri Hizmetleri KB", "internal_kb", "document", "weekly"),
            ExternalSource("√úr√ºn Katalog API", "api_endpoint", "api", "hourly")
        ]
    
    def collect_product_specifications(self, product_name: str):
        """√úr√ºn teknik √∂zelliklerini topla"""
        # √ñrnek: √úr√ºn API'sinden bilgi √ßekme
        try:
            # Bu ger√ßek bir API call olacak
            specs = {
                'marka': '√ñrnek Marka',
                'kategori': 'Bebek Gƒ±dasƒ±',
                'malzemeler': 'Organik malzemeler',
                'saklama_ko≈üullarƒ±': 'Serin ve kuru yerde',
                'kullanƒ±m_talimatlarƒ±': 'Yemekten √∂nce karƒ±≈ütƒ±rƒ±n'
            }
            
            content = f"√úr√ºn: {product_name}\n"
            content += "\n".join([f"{k}: {v}" for k, v in specs.items()])
            
            self.rag_kb.add_external_source(
                f"√ºr√ºn_specs_{product_name}",
                content,
                "internal_api",
                "api"
            )
            
        except Exception as e:
            print(f"‚ö†Ô∏è √úr√ºn bilgisi alƒ±namadƒ±: {e}")
    
    def collect_troubleshooting_guides(self):
        """Sorun giderme kƒ±lavuzlarƒ±nƒ± topla"""
        guides = {
            'kargo_sorunlarƒ±': """
            Kargo Sorunlarƒ± i√ßin √á√∂z√ºmler:
            1. Geciken kargolar i√ßin kargo firmasƒ± ile ileti≈üime ge√ßin
            2. Hasarlƒ± paketler i√ßin fotoƒüraf √ßekin ve m√º≈üteri hizmetlerine bildirin
            3. Kayƒ±p kargolar i√ßin takip numarasƒ± ile sorgulatƒ±n
            """,
            '√ºr√ºn_kalitesi': """
            Kalite Sorunlarƒ± i√ßin Aksiyonlar:
            1. Defolu √ºr√ºnler i√ßin kalite kontrol s√ºrecini g√∂zden ge√ßirin
            2. Tedarik√ßi denetimi yapƒ±n
            3. ƒ∞ade/deƒüi≈üim s√ºrecini hƒ±zlandƒ±rƒ±n
            """,
            'beden_uyumsuzluƒüu': """
            Beden Sorunlarƒ± i√ßin √á√∂z√ºmler:
            1. Beden tablosunu g√ºncelleyin
            2. Model fotoƒüraflarƒ±nƒ± standardize edin
            3. M√º≈üteri yorumlarƒ±nda beden √∂nerilerini payla≈üƒ±n
            """
        }
        
        for guide_name, content in guides.items():
            self.rag_kb.add_external_source(
                f"guide_{guide_name}",
                content,
                "internal_knowledge_base",
                "document"
            )

def main():
    """Ger√ßek zamanlƒ± RAG sistemi demo"""
    
    print("üöÄ GER√áEK ZAMANLI RAG Sƒ∞STEMƒ∞ v1.0")
    print("üìä Otomatik Yorum Analizi + Harici Kaynak Entegrasyonu")
    print("="*70)
    
    # Sistem kurulumu
    monitor = RealTimeCommentMonitor(check_interval=60)  # 1 dakika test i√ßin
    data_collector = ExternalDataCollector(monitor.rag_kb)
    
    print("üîß Sistem hazƒ±rlanƒ±yor...")
    
    # Harici verileri topla
    data_collector.collect_troubleshooting_guides()
    data_collector.collect_product_specifications("Bebek Mamasƒ±")
    
    print("‚úÖ Harici veriler y√ºklendi")
    
    # Kullanƒ±cƒ± se√ßimi
    print("\nüîç Hangi modu √ßalƒ±≈ütƒ±rmak istiyorsunuz?")
    print("1. üîÑ Ger√ßek Zamanlƒ± ƒ∞zleme (S√ºrekli)")
    print("2. üìä Tek Seferlik RAG Analizi")
    print("3. üß™ RAG Bilgi Tabanƒ± Testi")
    print("4. üö™ √áƒ±kƒ±≈ü")
    
    choice = input("\nSe√ßiminiz (1-4): ").strip()
    
    if choice == '1':
        print("\nüöÄ Ger√ßek zamanlƒ± izleme ba≈ülatƒ±lƒ±yor...")
        print("üí° Durdurmak i√ßin Ctrl+C basƒ±n")
        try:
            monitor.start_monitoring()
        except KeyboardInterrupt:
            print("\n‚èπÔ∏è ƒ∞zleme durduruldu")
    
    elif choice == '2':
        print("\nüìä Tek seferlik RAG analizi yapƒ±lƒ±yor...")
        comments = monitor.load_current_comments()
        enhanced_analysis = monitor.enhanced_analysis_with_rag(comments)
        
        # Sonu√ßlarƒ± g√∂ster
        if 'analysis_results' in enhanced_analysis:
            print(f"\n‚úÖ {enhanced_analysis['new_comments_count']} yorum analiz edildi")
            
            # RAG baƒülamƒ±nƒ± g√∂ster
            rag_context = enhanced_analysis['analysis_results'].get('rag_context', {})
            if rag_context:
                print(f"\nüß† RAG BAƒûLAMI:")
                for category, context in rag_context.items():
                    print(f"   üìã {category.upper()}:")
                    for solution in context.get('external_solutions', []):
                        print(f"      üîó {solution['source_name']}: {solution['content'][:100]}...")
        
        # AI √∂nerileri
        ai_recs = enhanced_analysis.get('ai_recommendations', {})
        if ai_recs and 'error' not in ai_recs:
            print(f"\nü§ñ AI √ñNERƒ∞LERƒ∞:")
            for category, rec in ai_recs.items():
                print(f"   üìã {category}: {rec['ai_suggestions'][:200]}...")
    
    elif choice == '3':
        print("\nüß™ RAG bilgi tabanƒ± test ediliyor...")
        
        test_queries = [
            "kargo gecikmesi nasƒ±l √ß√∂z√ºl√ºr",
            "√ºr√ºn kalitesi sorunlarƒ± i√ßin ne yapƒ±lmalƒ±",
            "beden uyumsuzluƒüu √ß√∂z√ºmleri"
        ]
        
        for query in test_queries:
            print(f"\nüîç Query: {query}")
            results = monitor.rag_kb.find_relevant_context(query, limit=2)
            
            for i, result in enumerate(results, 1):
                print(f"   {i}. {result['source_name']}")
                print(f"      üìä Benzerlik: %{result['similarity']*100:.1f}")
                print(f"      üìù ƒ∞√ßerik: {result['content'][:150]}...")
    
    elif choice == '4':
        print("üëã Sistem kapatƒ±lƒ±yor...")
    
    else:
        print("‚ùå Ge√ßersiz se√ßim!")

if __name__ == "__main__":
    main() 